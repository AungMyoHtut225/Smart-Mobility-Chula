{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allocator_type = 'BFC' #A \"Best-fit with coalescing\" algorithm, simplified from a version of dlmalloc.\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "# config.gpu_options.allow_growth = True\n",
    "# set_session(tf.Session(config=config)) \n",
    "\n",
    "## LIMIT GPU USAGE\n",
    "config = tf.ConfigProto(log_device_placement=True)  \n",
    "config.gpu_options.allow_growth = True  # don't pre-allocate memory; allocate as-needed\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.95  # limit memory to be allocated\n",
    "set_session(tf.Session(config=config)) # create sess w/ above settings\n",
    "print(tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "if tf.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# keras example imports\n",
    "from keras.models import load_model\n",
    " \n",
    "## extra imports to set GPU options\n",
    "import tensorflow as tf\n",
    "from keras import backend as k\n",
    "\n",
    "k.get_session().close()\n",
    "###################################\n",
    "# TensorFlow wizardry\n",
    "config = tf.ConfigProto()\n",
    " \n",
    "# Don't pre-allocate memory; allocate as-needed\n",
    "config.gpu_options.allow_growth = True\n",
    " \n",
    "# Only allow a total of half the GPU memory to be allocated\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.95\n",
    " \n",
    "# Create a session with the above options specified.\n",
    "k.tensorflow_backend.set_session(tf.Session(config=config))\n",
    "###################################\n",
    "print(tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "import os\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function is to get the time string like h:m:s\n",
    "#========================================================================================\n",
    "def getTime(time):\n",
    "    time=time%(24*3600)\n",
    "    hours=time//3600\n",
    "    time%=3600\n",
    "    minutes=time//60\n",
    "    time%=60\n",
    "    seconds=time\n",
    "    periods=[('hours',int(hours)),('minutes',int(minutes)),('seconds',int(seconds))]\n",
    "    time_string=':'.join('{}'.format(value) for name,value in periods)\n",
    "    return time_string\n",
    "#========================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "dirpath = os.getcwd()\n",
    "path = dirpath + '/LSTMExperimentResults_AfterDefense/1%/RMSE_Confidence_Interval (epoch= 10, batch = 20 , neurons = 10).csv'\n",
    "myfile1 = open(path,'w', newline='')\n",
    "writer1 = csv.writer(myfile1)\n",
    "heading =['Samples','Number of Observations','RMSEValues','Mean','Standard Errors','Upper Bound','Lower Bound','Execution Time']\n",
    "writer1.writerow(heading)\n",
    "myfile1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/\n",
    "https://machinelearningmastery.com/time-series-forecasting-long-short-term-memory-network-python/\n",
    "https://machinelearningmastery.com/multi-step-time-series-forecasting-long-short-term-memory-networks-python/\n",
    "https://machinelearningmastery.com/models-sequence-prediction-recurrent-neural-networks/\n",
    "https://machinelearningmastery.com/how-to-develop-rnn-models-for-human-activity-recognition-time-series-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  var1(t)  \\\n",
      "1        0.0        0.0        0.0        0.0        0.0        0.0        0   \n",
      "2        0.0        0.0        0.0        0.0        0.0        0.0        0   \n",
      "3        0.0        0.0        0.0        0.0        0.0        0.0        0   \n",
      "4        0.0        0.0        0.0        0.0        0.0        0.0        0   \n",
      "5        0.0        0.0        0.0        0.0        0.0        0.0        0   \n",
      "\n",
      "   var2(t)  var3(t)  var4(t)  var5(t)  var6(t)  \n",
      "1        0        0        0        0        0  \n",
      "2        0        0        0        0        0  \n",
      "3        0        0        0        0        0  \n",
      "4        0        0        0        0        0  \n",
      "5        0        0        0        0        0  \n",
      "(14480, 6) 14480 (14480,)\n",
      "(14480, 1, 6) (14480,) (3619, 1, 6) (3619,)\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "   var1(t-5)  var2(t-5)  var3(t-5)  var4(t-5)  var5(t-5)  var6(t-5)  \\\n",
      "5        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "6        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "7        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "8        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "9        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "\n",
      "   var1(t-4)  var2(t-4)  var3(t-4)  var4(t-4)  ...  var3(t-1)  var4(t-1)  \\\n",
      "5        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "6        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "7        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "8        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "9        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "\n",
      "   var5(t-1)  var6(t-1)  var1(t)  var2(t)  var3(t)  var4(t)  var5(t)  var6(t)  \n",
      "5        0.0        0.0        0        0        0        0        0        0  \n",
      "6        0.0        0.0        0        0        0        0        0        0  \n",
      "7        0.0        0.0        0        0        0        0        0        0  \n",
      "8        0.0        0.0        0        0        0        0        0        0  \n",
      "9        0.0        0.0        0        0        0        0        0        0  \n",
      "\n",
      "[5 rows x 36 columns]\n",
      "(14480, 30) 14480 (14480,)\n",
      "(14480, 5, 6) (14480,) (3615, 5, 6) (3615,)\n",
      "    var1(t-10)  var2(t-10)  var3(t-10)  var4(t-10)  var5(t-10)  var6(t-10)  \\\n",
      "10         0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "11         0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "12         0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "13         0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "14         0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "\n",
      "    var1(t-9)  var2(t-9)  var3(t-9)  var4(t-9)  ...  var3(t-1)  var4(t-1)  \\\n",
      "10        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "11        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "12        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "13        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "14        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
      "\n",
      "    var5(t-1)  var6(t-1)  var1(t)  var2(t)  var3(t)  var4(t)  var5(t)  var6(t)  \n",
      "10        0.0        0.0        0        0        0        0        0        0  \n",
      "11        0.0        0.0        0        0        0        0        0        0  \n",
      "12        0.0        0.0        0        0        0        0        0        0  \n",
      "13        0.0        0.0        0        0        0        0        0        0  \n",
      "14        0.0        0.0        0        0        0        0        0        0  \n",
      "\n",
      "[5 rows x 66 columns]\n",
      "(14480, 60) 14480 (14480,)\n",
      "(14480, 10, 6) (14480,) (3610, 10, 6) (3610,)\n",
      "    var1(t-15)  var2(t-15)  var3(t-15)  var4(t-15)  var5(t-15)  var6(t-15)  \\\n",
      "15         0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "16         0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "17         0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "18         0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "19         0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "\n",
      "    var1(t-14)  var2(t-14)  var3(t-14)  var4(t-14)  ...  var3(t-1)  var4(t-1)  \\\n",
      "15         0.0         0.0         0.0         0.0  ...        0.0        0.0   \n",
      "16         0.0         0.0         0.0         0.0  ...        0.0        0.0   \n",
      "17         0.0         0.0         0.0         0.0  ...        0.0        0.0   \n",
      "18         0.0         0.0         0.0         0.0  ...        0.0        0.0   \n",
      "19         0.0         0.0         0.0         0.0  ...        0.0        0.0   \n",
      "\n",
      "    var5(t-1)  var6(t-1)  var1(t)  var2(t)  var3(t)  var4(t)  var5(t)  var6(t)  \n",
      "15        0.0        0.0        0        0        0        0        0        0  \n",
      "16        0.0        0.0        0        0        0        0        0        0  \n",
      "17        0.0        0.0        0        0        0        0        0        0  \n",
      "18        0.0        0.0        0        0        0        0        0        0  \n",
      "19        0.0        0.0        0        0        0        0        0        0  \n",
      "\n",
      "[5 rows x 96 columns]\n",
      "(14480, 90) 14480 (14480,)\n",
      "(14480, 15, 6) (14480,) (3605, 15, 6) (3605,)\n",
      "    var1(t-30)  var2(t-30)  var3(t-30)  var4(t-30)  var5(t-30)  var6(t-30)  \\\n",
      "30         0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "31         0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "32         0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "33         0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "34         0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "\n",
      "    var1(t-29)  var2(t-29)  var3(t-29)  var4(t-29)  ...  var3(t-1)  var4(t-1)  \\\n",
      "30         0.0         0.0         0.0         0.0  ...        0.0        0.0   \n",
      "31         0.0         0.0         0.0         0.0  ...        0.0        0.0   \n",
      "32         0.0         0.0         0.0         0.0  ...        0.0        0.0   \n",
      "33         0.0         0.0         0.0         0.0  ...        0.0        0.0   \n",
      "34         0.0         0.0         0.0         0.0  ...        0.0        0.0   \n",
      "\n",
      "    var5(t-1)  var6(t-1)  var1(t)  var2(t)  var3(t)  var4(t)  var5(t)  var6(t)  \n",
      "30        0.0        0.0        0        0        0        0        0        0  \n",
      "31        0.0        0.0        0        0        0        0        0        0  \n",
      "32        0.0        0.0        0        0        0        0        0        0  \n",
      "33        0.0        0.0        0        0        0        0        0        0  \n",
      "34        0.0        0.0        0        0        0        0        0        0  \n",
      "\n",
      "[5 rows x 186 columns]\n",
      "(14480, 180) 14480 (14480,)\n",
      "(14480, 30, 6) (14480,) (3590, 30, 6) (3590,)\n",
      "    var1(t-60)  var2(t-60)  var3(t-60)  var4(t-60)  var5(t-60)  var6(t-60)  \\\n",
      "60         0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "61         0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "62         0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "63         0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "64         0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "\n",
      "    var1(t-59)  var2(t-59)  var3(t-59)  var4(t-59)  ...  var3(t-1)  var4(t-1)  \\\n",
      "60         0.0         0.0         0.0         0.0  ...        0.0        0.0   \n",
      "61         0.0         0.0         0.0         0.0  ...        0.0        0.0   \n",
      "62         0.0         0.0         0.0         0.0  ...        0.0        0.0   \n",
      "63         0.0         0.0         0.0         0.0  ...        0.0        0.0   \n",
      "64         0.0         0.0         0.0         0.0  ...        0.0        0.0   \n",
      "\n",
      "    var5(t-1)  var6(t-1)  var1(t)  var2(t)  var3(t)  var4(t)  var5(t)  var6(t)  \n",
      "60        0.0        0.0        0        0        0        0        0        0  \n",
      "61        0.0        0.0        0        0        0        0        0        0  \n",
      "62        0.0        0.0        0        0        0        0        0        0  \n",
      "63        0.0        0.0        0        0        0        0        0        0  \n",
      "64        0.0        0.0        0        0        0        0        0        0  \n",
      "\n",
      "[5 rows x 366 columns]\n",
      "(14480, 360) 14480 (14480,)\n",
      "(14480, 60, 6) (14480,) (3560, 60, 6) (3560,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "# specify the number of lag hours\n",
    "list_n_mins = [1,5,10,15,30,60]\n",
    "\n",
    "#percentage = ['5%','10%','15%','20%','25%','30%','35%','40%','45%','50%']\n",
    "percentage = ['1%']\n",
    "\n",
    "\n",
    "for n_mins in list_n_mins:\n",
    "    \n",
    "    for percent in percentage:\n",
    "        \n",
    "        import time\n",
    "        start_time = time.time()\n",
    "\n",
    "        # load dataset\n",
    "        dirpath = os.getcwd()\n",
    "        dataset = read_csv(dirpath + '/datasetForLSTM/60_'+percent+'_Allcombine.csv', header=0, index_col=0)\n",
    "        values = dataset.values\n",
    "\n",
    "        epochs = 10\n",
    "        batch_size = 20\n",
    "        neurons = 10\n",
    "\n",
    "        n_features = 6\n",
    "        # frame as supervised learning\n",
    "        reframed = series_to_supervised(values, n_mins, 1)\n",
    "        print(reframed.head())\n",
    "\n",
    "        # drop columns we don't want to predict\n",
    "        # for number of mins  = 1, drop columns ==> [6,7,8,9,10] , index 11 for gridlock\n",
    "        # for number of mins  = 5, drop columns ==> [30,31,32,33,34] , index 35 for gridlock\n",
    "        # for number of mins  = 10, drop columns ==> [60,61,62,63,64] , index 65 for gridlock\n",
    "        # for number of mins  = 15, drop columns ==> [90,91,92,93,94] , index 95 for gridlock\n",
    "        # for number of mins  = 30, drop columns ==> [180,181,182,183,184] , index 95 for gridlock\n",
    "        # for number of mins  = 60, drop columns ==> [360,361,362,363,364] , index 365 for gridlock\n",
    "        # for number of mins  = 90, drop columns ==> [540,541,542,543,544] , index 545 for gridlock\n",
    "        \n",
    "        if n_mins == 1:\n",
    "            reframed.drop(reframed.columns[[6,7,8,9,10]], axis=1, inplace=True)\n",
    "        if n_mins == 5:\n",
    "            reframed.drop(reframed.columns[[30,31,32,33,34]], axis=1, inplace=True)\n",
    "        if n_mins == 10:\n",
    "            reframed.drop(reframed.columns[[60,61,62,63,64]], axis=1, inplace=True)\n",
    "        if n_mins == 15:\n",
    "            reframed.drop(reframed.columns[[90,91,92,93,94]], axis=1, inplace=True)\n",
    "        if n_mins == 30:\n",
    "            reframed.drop(reframed.columns[[180,181,182,183,184]], axis=1, inplace=True)\n",
    "        if n_mins == 60:\n",
    "            reframed.drop(reframed.columns[[360,361,362,363,364]], axis=1, inplace=True)\n",
    "            \n",
    "        # reframed.to_csv(dirpath + '/datasetForLSTM/60_5%_Allcombine_reframed.csv',index=False )\n",
    "        #print(reframed.head())\n",
    "\n",
    "\n",
    "\n",
    "        reframed.columns\n",
    "\n",
    "        # split into train and test sets\n",
    "        values = reframed.values\n",
    "        n_train_mins =80 * 181\n",
    "        train = values[:n_train_mins, :]\n",
    "        test = values[n_train_mins:, :]\n",
    "\n",
    "        # split into input and outputs\n",
    "        n_obs = n_mins * n_features\n",
    "        train_X, train_y = train[:, :n_obs], train[:, -1]\n",
    "        test_X, test_y = test[:, :n_obs], test[:, -1]\n",
    "\n",
    "        print(train_X.shape, len(train_X), train_y.shape)\n",
    "        # reshape input to be 3D [samples, timesteps, features]\n",
    "        train_X = train_X.reshape((train_X.shape[0], n_mins, n_features))\n",
    "        test_X = test_X.reshape((test_X.shape[0], n_mins, n_features))\n",
    "        print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    "\n",
    "        # design network\n",
    "        model = Sequential()\n",
    "        model.add(LSTM(neurons, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "        # fit network\n",
    "        history = model.fit(train_X, train_y, epochs=epochs, batch_size=batch_size, validation_data=(test_X, test_y), verbose=0, shuffle=False)\n",
    "        # plot history\n",
    "        pyplot.plot(history.history['loss'], label='train')\n",
    "        pyplot.plot(history.history['val_loss'], label='test')\n",
    "        pyplot.xlabel('epoch')\n",
    "        pyplot.ylabel('loss')\n",
    "        pyplot.legend()\n",
    "        pyplot.savefig(dirpath + '/LSTMExperimentResults_AfterDefense/1%/'+percent+'_'+str(n_mins)+'min_'+str(epochs)+'epochs_'+str(batch_size)+'batch_size_'+str(neurons)+'neurons.png')\n",
    "        pyplot.clf()\n",
    "        # pyplot.show()\n",
    "\n",
    "\n",
    "        # make a prediction\n",
    "        yhat = model.predict(test_X)\n",
    "\n",
    "#         temp_yhat = yhat \n",
    "#         temp_yhat = [np.round(num) for num in yhat]\n",
    "#         pyplot.plot(test_y,  'r-',label='actual')\n",
    "#         pyplot.show()\n",
    "#         pyplot.plot(temp_yhat, 'b-',label='predict')\n",
    "#         pyplot.show()\n",
    "\n",
    "        test_X.shape\n",
    "\n",
    "        repeats  = 10\n",
    "        rmse_list = list()\n",
    "        \n",
    "        acutal_predicted_df = DataFrame()\n",
    "        acutal_predicted_df['actual']= test_y\n",
    "        acutal_predicted_df['predicted']= yhat\n",
    "        acutal_predicted_df.to_csv(dirpath + '/LSTMExperimentResults_AfterDefense/1%/'+percent+'_'+str(n_mins)+'min_'+str(epochs)+'epochs_'+str(batch_size)+'batch_size_'+str(neurons)+'neurons.csv', index=False)\n",
    "\n",
    "\n",
    "        for r in range(repeats):\n",
    "\n",
    "            # make a prediction\n",
    "            test_X, test_y = test[:, :n_obs], test[:, -1]\n",
    "            test_X = test_X.reshape((test_X.shape[0], n_mins, n_features))\n",
    "            yhat = model.predict(test_X)\n",
    "            yhat.shape\n",
    "\n",
    "\n",
    "            test_X = test_X.reshape((test_X.shape[0], test_X.shape[1]*test_X.shape[2]))\n",
    "            test_y = test_y.reshape((len(test_y), 1))\n",
    "\n",
    "            # invert scaling for forecast\n",
    "            inv_yhat = concatenate((yhat, test_X), axis=1)\n",
    "\n",
    "\n",
    "            #print(tabulate(inv_yhat, headers=['inv_yhat'], tablefmt='orgtbl'))\n",
    "\n",
    "            inv_y = concatenate((test_y, test_X), axis=1)\n",
    "            #print(tabulate(inv_y, headers=['inv_y'], tablefmt='orgtbl'))\n",
    "\n",
    "            # calculate RMSE\n",
    "            rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "            rmse_list.append(rmse)\n",
    "\n",
    "        import numpy as np\n",
    "        import scipy.stats\n",
    "        import csv\n",
    "\n",
    "\n",
    "        a = 1.0 * np.array(rmse_list)\n",
    "        n = len(a)\n",
    "        mean, se = np.mean(a), scipy.stats.sem(a)\n",
    "        h = se * scipy.stats.t.ppf((1 + 0.95) / 2., n-1)\n",
    "\n",
    "\n",
    "        elapsed_time = getTime(time.time() - start_time)\n",
    "\n",
    "        myfile = open(dirpath + '/LSTMExperimentResults_AfterDefense/1%/RMSE_Confidence_Interval (epoch= 10, batch = 20 , neurons = 10).csv', 'a', newline='')\n",
    "        writer = csv.writer(myfile)\n",
    "        with myfile:\n",
    "            writer.writerow(\n",
    "                [percent,n_mins , rmse_list,mean, se, mean-h, mean+h,elapsed_time])    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "GridlockPredictionUsingLSTM(27.02.2020).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
